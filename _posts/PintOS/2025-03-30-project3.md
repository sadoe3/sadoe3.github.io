---
title: "Project 3: Memory"

categories:
    - pintos

tags:
    - [Operating Systems, PintOS, Linux, ]

toc: true
toc_label: "Table of Contents"
toc_sticky: true

date: 2025-03-30
---

# Memory
- The third project enhanced the PintOS operating system regarding memory:
  1. implement supplemenatal page table per each process
  2. implement page demanding so that it handles the page fault
    - then pintos becomes able to manage stack growth
  3. 

## Part 1: Supplemantal Page Table

### Objective
- The goal is to implement the supplemental page table so that the pages are not allocated at boot time
  * they are allocated only if it's required
  * this is called page demanding
- Moreover, once pintos supports page demanding then, it becomes possible to extend the stack area
  * because in order to do so, it's required to handle page fault which is managed by page demanding

### Current Problem
- The original `load_segment()` allocates the pages for each segment.

  <details markdown="1">
  <summary><b>Click</b> to see the original code</summary>

  ```c
  static bool
  load_segment (struct file *file, off_t ofs, uint8_t *upage,
                uint32_t read_bytes, uint32_t zero_bytes, bool writable) 
  {
    ASSERT ((read_bytes + zero_bytes) % PGSIZE == 0);
    ASSERT (pg_ofs (upage) == 0);
    ASSERT (ofs % PGSIZE == 0);

    file_seek (file, ofs);
    while (read_bytes > 0 || zero_bytes > 0) 
      {
        /* Calculate how to fill this page.
          We will read PAGE_READ_BYTES bytes from FILE
          and zero the final PAGE_ZERO_BYTES bytes. */
        size_t page_read_bytes = read_bytes < PGSIZE ? read_bytes : PGSIZE;
        size_t page_zero_bytes = PGSIZE - page_read_bytes;

        /* Get a page of memory. */
        uint8_t *kpage = palloc_get_page (PAL_USER);
        if (kpage == NULL)
          return false;

        /* Load this page. */
        if (file_read (file, kpage, page_read_bytes) != (int) page_read_bytes)
          {
            palloc_free_page (kpage);
            return false; 
          }
        memset (kpage + page_read_bytes, 0, page_zero_bytes);

        /* Add the page to the process's address space. */
        if (!install_page (upage, kpage, writable)) 
          {
            palloc_free_page (kpage);
            return false; 
          }

        /* Advance. */
        read_bytes -= page_read_bytes;
        zero_bytes -= page_zero_bytes;
        upage += PGSIZE;
      }
    return true;
  }
  ```
  </details>

### Solution
- 

### Implementation Details
- **`timer.c`**
  - **`timer_sleep()`**
    - Replaced `thread_yield()` with `thread_sleep()`.
      <details markdown="1">
      <summary><b>Click</b> to see the refined code</summary>

      ```c
      void
      timer_sleep(int64_t ticks)
      {
        int64_t start = timer_ticks();
        ASSERT (intr_get_level () == INTR_ON);

        while(timer_elapsed(start) < ticks)
          thread_sleep(ticks);
      }
      ```
      </details>
  - **`timer_interrupt()`**
    - Added a call to `thread_wakeup()` with `timer_ticks()` value.
      <details markdown="1">
      <summary><b>Click</b> to see the refined code</summary>

      ```c
      static void
      timer_interrupt (struct intr_frame *args UNUSED)
      {
        ticks++;
        thread_tick ();

        thread_wakeup(ticks);
      }
      ```
      </details>
- **`thread.h`**
  - **`struct thread`**
    - Added `int64_t tick_wakeup` for wake-up time.
      <details markdown="1">
      <summary><b>Click</b> to see the refined code</summary>

      ```c
      /* Shared between thread.c and synch.c. */
      struct list_elem elem;              /* List element. */

      int64_t tick_wakeup;                /* Tick till wake up */
      ```
      </details>

- **`thread.c`**
  - **`static struct list sleep_list`**
    - New list for managing sleeping threads.
      <details markdown="1">
      <summary><b>Click</b> to see the refined code</summary>

      ```c
      /* List of all processes.  Processes are added to this list
        when they are first scheduled and removed when they exit. */
      static struct list all_list;

      /* List of processes in THREAD_BLOCKED state. Processes are added to this list
        when they are called with thread_sleep() and removed when wakeup() is called */
      static struct list sleep_list;
      ```
      </details>
  - **`thread_init()`**
    - Initialized `sleep_list`.
      <details markdown="1">
      <summary><b>Click</b> to see the refined code</summary>

      ```c
      void
      thread_init (void) 
      {
        ASSERT (intr_get_level () == INTR_OFF);

        lock_init (&tid_lock);
        list_init (&ready_list);
        list_init (&all_list);
        list_init (&sleep_list);

        /* Set up a thread structure for the running thread. */
        initial_thread = running_thread ();
        init_thread (initial_thread, "main", PRI_DEFAULT);
        initial_thread->status = THREAD_RUNNING;
        initial_thread->tid = allocate_tid ();
      }
      ```
      </details>
 

### Conclusion
- This modification eliminates busy waiting, improving CPU efficiency in PintOS.


## Part 2: Priority
- Implementing Priority Scheduling and Preemption.

### Objective
- The aim is to replace PintOS's **FIFO** scheduling with a **priority-based** system and add **preemption** to prioritize high-priority threads effectively.

### Current Problem
- **FIFO Scheduling**


- **No Preemption**
  * When high-priority threads wake up, they are not executed immediately because the current PintOS system does not support preemption.

### Solution
- **Creation/Unblocking**:


### Implementation Details
- **`thread.h`**
  - **`struct thread`**
    - Added `lock_to_wait`, `original_priority`, `donors`, `donelem`.
      <details markdown="1">
      <summary><b>Click</b> to see the refined code</summary>

      ```c
      int64_t tick_wakeup;                /* Tick till wake up */
      struct lock *lock_to_wait;          /* Address of the lock to wait */
      int original_priority;              /* Original Priority value */
      struct list donors;                 /* Doners for priority inversion */
      struct list_elem donelem;           /* List element for donors list */
      ```
      </details>

- **`thread.c`**
  - **`init_thread()`**
    - Initializes `wait_to_lock`, `original_priority`, `donors`.
      <details markdown="1">
      <summary><b>Click</b> to see the refined code</summary>

      ```c
      static void
      init_thread (struct thread *t, const char *name, int priority)
      {
        enum intr_level old_level;

        ASSERT (t != NULL);
        ASSERT (PRI_MIN <= priority && priority <= PRI_MAX);
        ASSERT (name != NULL);

        memset (t, 0, sizeof *t);
        t->status = THREAD_BLOCKED;
        strlcpy (t->name, name, sizeof t->name);
        t->stack = (uint8_t *) t + PGSIZE;
        t->priority = priority;
        t->magic = THREAD_MAGIC;


        t->lock_to_wait = NULL;
        t->original_priority = priority;
        list_init(&t->donors);


        old_level = intr_disable ();
        list_push_back (&all_list, &t->allelem);
        intr_set_level (old_level);
      }
      ```
      </details>
 

### Conclusion
- This enhancement introduces priority scheduling, preemption, and priority donation, making PintOS more responsive and efficient.

### Improved Grade


## Final Thoughts
- Together, these improvements transform PintOS into a more robust OS, optimizing resource use and thread management.


[Top](#){: .btn .btn--primary }{: .align-right}