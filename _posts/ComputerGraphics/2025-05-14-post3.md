---
title: "Computer Graphics: Camera"

categories:
    - graphics

tags:
    - [computer graphics, graphics, ray tracing, camera physics, depth of field, focal length, aperture, anti-aliasing, motion blur, circle of confusion]

toc: true
toc_label: "Table of Contents"
toc_sticky: true

date: 2025-05-14
---

# **Camera**
- This report explains the fundamental principles of how a camera operates, both in the physical world and in the context of computer graphics.
- It covers concepts from light convergence and focusing to the implementation of visual effects like blur and anti-aliasing.

---

## **How a Camera Forms an Image**

### **Image Point and Image Plane**

- A camera forms an image by converging light rays from an object onto a sensor.
- While an object reflects light in many directions, a camera's lens focuses these rays to a single point, called the **Image Point**, on a 2D surface known as the **Image Plane**.
    - These points collectively form an inverted image on the sensor.

### **Circle of Confusion (CoC)**

- When light rays from a point on an object do not perfectly converge on the image plane, they form a small circle instead of a single point. This is known as the **Circle of Confusion (CoC)**. The size of the CoC directly determines the sharpness of an object in the final image. A smaller CoC results in a sharper, more in-focus image.
- The position of the image plane is dependent on the object's distance from the lens and the lens's position itself. By adjusting the lens, a photographer can control the size of the CoC for objects at different distances, thus bringing them into focus.

### **Focal Point and Focal Plane**

- The concepts of **Focal Point** and **Focal Plane** are specific to light rays from objects at an infinite distance, where the rays are effectively parallel. In this scenario, all parallel rays converge to a single point on the **Focal Plane**. This point is the **Focal Point**. The focal point is a fixed property of a lens and serves as a conceptual reference rather than an active component for constructing the image of a nearby object, which is handled by the image point. The principal focal point is the focal point that lies on the central axis of the lens.

### **Focal Length**

- **Focal Length** is the distance between the optical center of a lens and its principal focal point. For a real-world camera, if the subject is at an infinite distance, the image plane is at the same location as the focal plane, so the focal length can be considered the distance from the lens's optical center to the image sensor.
- Lenses are classified as either prime (fixed focal length) or zoom (variable focal length). A zoom lens changes its focal length by moving its internal elements, which alters the field of view. The distance between the camera's optical center and the object being photographed is called the **Working Distance**.

---

## **Field of View and Zooming**

### The relationship between angle of view and local length

- The **angle of view** is intrinsically linked to the focal length. A **longer focal length** (telephoto lens) results in a narrower angle of view, which magnifies the scene and produces a "zoomed-in" effect. Conversely, a **shorter focal length** (wide-angle lens) provides a wider angle of view, capturing more of the scene and creating a "zoomed-out" effect.

### Viewport

- In **computer graphics**, the **viewport** is the 2D window on the screen where the 3D scene is rendered. It represents the final rendered image and can be considered the digital equivalent of the physical image plane. Unlike real-world cameras, computer graphics engines often allow the **field of view (FOV)** to be set independently of the focal length for greater creative control, though this is not physically accurate.

---

## **Implementing Visual Effects**

### **Defocus Blur (Depth of Field)**

- **Defocus blur**, commonly known as **Depth of Field (DoF)**, occurs when objects are not within the camera's focus range, causing their CoC to become perceptibly large. In real-time rendering, simulating this physical process is computationally expensive. Therefore, a common alternative is a post-processing technique using a **G-Buffer**.
- A **G-Buffer** (Geometry Buffer) stores per-pixel data, including depth, position, and surface normals. A post-processing shader then uses this depth information to calculate a blur radius for each pixel based on its distance from the camera's focal plane. Pixels within the DoF receive little to no blur, while pixels outside of it are blurred according to their distance from the focal plane, simulating the defocus effect.

### **Focusing Mechanism**

- The process of focusing a camera involves selecting a specific **image plane** to be sharp. The relationship between focal length, subject distance, and image distance is governed by the **Thin Lens Equation**:

$$
{1\over f} = {1\over u} + {1\over v}
$$

- where:
    - f is the focal length of the lens.
    - u is the distance from the lens to the object (focus distance).
    - v is the distance from the lens to the image sensor (image distance).
- For a lens with a fixed focal length, focusing on an object at a certain distance requires adjusting the distance of the lens from the sensor. This effectively selects the image plane where the object's light rays will converge perfectly.

### **Aperture and Depth of Field (DoF)**

- The **aperture** is the opening that controls the amount of light entering the lens. A larger aperture allows light from a wider range of angles, making it more challenging for the lens to converge all rays to a single point. This leads to a shallower DoF, where only objects at the focal plane are sharp, and those in front of or behind it become more blurred.
- The aperture size is measured by the **f-number** (N), which is the ratio of the focal length (f) to the aperture's diameter (D):
    - $N = {f\over D}$
- A higher f-number corresponds to a smaller aperture, resulting in a larger DoF and less blur for objects outside the focal plane. Conversely, a lower f-number means a larger aperture, which produces a shallower DoF with more pronounced blur.

### **Anti-Aliasing**

- **Aliasing** is the appearance of jagged or stair-stepped edges in digital images. It occurs because a single pixel represents a small area of the scene but is often assigned a single color value based on a single point sample. This discards color information from other parts of the pixel's area, leading to visual artifacts.
- To fix this, **anti-aliasing** techniques take multiple color samples within a single pixel's area and average them to determine the final pixel color. **Supersampling (SSAA)** is a technique that uses a regular grid within each pixel to take multiple samples, which are then averaged to produce a smoother image.

### **Motion Blur**

- **Motion blur** is an effect that simulates the streaking of objects in motion, as a result of a short exposure time. This is implemented by averaging the color of a pixel across multiple frames or time steps, similar to how defocus blur is achieved by averaging samples across a spatial area. The final color of a pixel is a blend of its colors at different moments in time, creating the illusion of motion.


[Top](#){: .btn .btn--primary }{: .align-right}
